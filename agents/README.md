# FactBench Multi-Agent System

A comprehensive multi-agent system for extracting, validating, and deploying product review data.

## ğŸ¤– Agents Overview

### 1. **ImageExtractorAgent**
- **Purpose**: Downloads all product images including galleries and high-res versions
- **Features**:
  - Handles lazy-loaded images
  - Downloads multiple resolutions (srcset)
  - Extracts alt text and captions
  - Creates organized folder structure
  - Generates image manifest

### 2. **TextExtractorAgent**
- **Purpose**: Extracts all text content including descriptions and specifications
- **Features**:
  - Extracts product descriptions
  - Captures features (pros/cons)
  - Gets page metadata
  - Preserves content structure
  - Handles dynamic content

### 3. **TableExtractorAgent**
- **Purpose**: Extracts all table data including comparisons and specifications
- **Features**:
  - Finds all HTML tables
  - Handles div-based tables
  - Extracts comparison matrices
  - Exports to CSV/JSON
  - Preserves cell formatting

### 4. **ReviewExtractorAgent**
- **Purpose**: Extracts product reviews and links to original reviews
- **Features**:
  - Extracts inline reviews
  - Follows review links
  - Captures ratings and dates
  - Links to source reviews
  - Calculates review statistics

### 5. **ValidationAgent**
- **Purpose**: Validates completeness and quality of extracted data
- **Features**:
  - Checks data completeness
  - Cross-validates sources
  - Calculates quality score
  - Generates recommendations
  - Creates action checklist

### 6. **DeploymentAgent**
- **Purpose**: Builds and deploys the site with validated data
- **Features**:
  - Pre-deployment checks
  - Data integration
  - Site building
  - GitHub deployment
  - Post-deployment validation

## ğŸš€ Quick Start

### Run All Agents

```bash
# Extract from zoopy.com and deploy
python agents/run_all_agents.py https://zoopy.com/best-robotic-pool-cleaners

# Extract and validate only (skip deployment)
python agents/run_all_agents.py https://zoopy.com/best-robotic-pool-cleaners --skip-deployment
```

### Run Individual Agents

```python
from agents import ImageExtractorAgent

# Run image extraction
agent = ImageExtractorAgent()
results = agent.run("https://zoopy.com/best-robotic-pool-cleaners")
```

## ğŸ“ Output Structure

```
extraction-workspace/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ products/          # Product images by ID
â”‚   â”‚   â”œâ”€â”€ beatbot-aquasense-2-pro/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.jpg
â”‚   â”‚   â”‚   â””â”€â”€ gallery-*.jpg
â”‚   â”‚   â””â”€â”€ [other-products]/
â”‚   â””â”€â”€ image_manifest.json
â”œâ”€â”€ text/
â”‚   â”œâ”€â”€ complete_text_content.json
â”‚   â”œâ”€â”€ product_descriptions.json
â”‚   â””â”€â”€ product_features.json
â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ all_tables_data.json
â”‚   â”œâ”€â”€ main_comparison_table.csv
â”‚   â””â”€â”€ consolidated_specifications.json
â”œâ”€â”€ reviews/
â”‚   â”œâ”€â”€ all_reviews_data.json
â”‚   â”œâ”€â”€ review_summary.json
â”‚   â””â”€â”€ reviews_[product-id].json
â””â”€â”€ validation/
    â”œâ”€â”€ validation_report_*.json
    â”œâ”€â”€ validation_summary.json
    â””â”€â”€ action_checklist.json
```

## ğŸ”§ Installation

1. Install Python dependencies:
```bash
pip install playwright beautifulsoup4 pandas requests
playwright install chromium
```

2. Install Node.js dependencies (for deployment):
```bash
npm install
```

## ğŸ“Š Validation Criteria

The ValidationAgent checks for:

- **Images**: Every product must have at least 1 image
- **Text**: Products need descriptions > 100 characters
- **Tables**: Complete comparison table required
- **Reviews**: At least 50% of products need reviews

Quality score must be â‰¥ 60% for deployment.

## ğŸš¨ Error Handling

All agents include:
- Automatic retry for failed downloads
- Progress saving for resumability
- Detailed error logging
- Graceful failure handling

## ğŸ“ Logs

Each agent creates timestamped logs in `extraction-workspace/logs/`:
- `ImageExtractorAgent_YYYYMMDD_HHMMSS.log`
- `TextExtractorAgent_YYYYMMDD_HHMMSS.log`
- etc.

## ğŸ”„ Workflow

1. **Extraction Phase** (Parallel)
   - ImageExtractorAgent
   - TextExtractorAgent  
   - TableExtractorAgent
   - ReviewExtractorAgent

2. **Validation Phase**
   - ValidationAgent analyzes all data
   - Generates quality report
   - Creates recommendations

3. **Deployment Phase**
   - DeploymentAgent integrates data
   - Builds static site
   - Deploys to GitHub Pages

## âš™ï¸ Configuration

Agents use these environment variables:
- `GITHUB_TOKEN`: For deployment (required)
- `WORKSPACE_DIR`: Custom workspace location (optional)

## ğŸ› Troubleshooting

### "No module named playwright"
```bash
pip install playwright
playwright install chromium
```

### "GitHub token not found"
```bash
export GITHUB_TOKEN="your_github_token"
```

### "Build failed"
Check Node.js dependencies:
```bash
npm install
npm run build
```

## ğŸ“ˆ Performance

- Parallel extraction: ~2-5 minutes
- Validation: ~30 seconds
- Build & deployment: ~2 minutes
- **Total time**: ~5-8 minutes

## ğŸ¤ Contributing

To add a new agent:

1. Extend `BaseAgent` class
2. Implement `extract()` method
3. Implement `validate_results()` method
4. Add to orchestrator pipeline

---

*Built for the FactBench project - Making product research transparent and data-driven*